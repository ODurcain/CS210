There were multiple issues I had noticed through test cases that were not caught in my manual testing. These were captured in the screenshots, but I think the most interesting one is the use of float points and that I had the amount of significant figures set too high. So most of my %.16f were changed to %.1f, but what I'm now realizing I should do is %d so that the value does not get altered by me at all. I had also missed some slight differences in the string comparisons, but these were minor like in TestSolver.java file I had an extra * in the string for the imaginary roots comparator and it made the test fail. 

I could see errors arising from manual testing for various reasons. Maybe misclicked a value when inutting, or are tired and not paying attention. One thing that is for sure is that the number of significant figures can play a role in causing errors. That is one thing I will be more cognizant of moving forward. The biggest reasons is always getting the same output and being able to compare and use the automated test cases as a debugger.